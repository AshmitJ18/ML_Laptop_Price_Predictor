{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "zxK7gF9wd9Ic",
        "outputId": "89fd5cb1-9621-4bed-b874-02f99d3593c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: crawl4ai in /usr/local/lib/python3.11/dist-packages (0.7.2)\n",
            "Requirement already satisfied: aiosqlite~=0.20 in /usr/local/lib/python3.11/dist-packages (from crawl4ai) (0.21.0)\n",
            "Requirement already satisfied: lxml~=5.3 in /usr/local/lib/python3.11/dist-packages (from crawl4ai) (5.4.0)\n",
            "Requirement already satisfied: litellm>=1.53.1 in /usr/local/lib/python3.11/dist-packages (from crawl4ai) (1.74.12)\n",
            "Requirement already satisfied: numpy<3,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from crawl4ai) (2.0.2)\n",
            "Requirement already satisfied: pillow>=10.4 in /usr/local/lib/python3.11/dist-packages (from crawl4ai) (11.3.0)\n",
            "Requirement already satisfied: playwright>=1.49.0 in /usr/local/lib/python3.11/dist-packages (from crawl4ai) (1.54.0)\n",
            "Requirement already satisfied: python-dotenv~=1.0 in /usr/local/lib/python3.11/dist-packages (from crawl4ai) (1.1.1)\n",
            "Requirement already satisfied: requests~=2.26 in /usr/local/lib/python3.11/dist-packages (from crawl4ai) (2.32.3)\n",
            "Requirement already satisfied: beautifulsoup4~=4.12 in /usr/local/lib/python3.11/dist-packages (from crawl4ai) (4.13.4)\n",
            "Requirement already satisfied: tf-playwright-stealth>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from crawl4ai) (1.2.0)\n",
            "Requirement already satisfied: xxhash~=3.4 in /usr/local/lib/python3.11/dist-packages (from crawl4ai) (3.5.0)\n",
            "Requirement already satisfied: rank-bm25~=0.2 in /usr/local/lib/python3.11/dist-packages (from crawl4ai) (0.2.2)\n",
            "Requirement already satisfied: aiofiles>=24.1.0 in /usr/local/lib/python3.11/dist-packages (from crawl4ai) (24.1.0)\n",
            "Requirement already satisfied: snowballstemmer~=2.2 in /usr/local/lib/python3.11/dist-packages (from crawl4ai) (2.2.0)\n",
            "Requirement already satisfied: pydantic>=2.10 in /usr/local/lib/python3.11/dist-packages (from crawl4ai) (2.11.7)\n",
            "Requirement already satisfied: pyOpenSSL>=24.3.0 in /usr/local/lib/python3.11/dist-packages (from crawl4ai) (25.1.0)\n",
            "Requirement already satisfied: psutil>=6.1.1 in /usr/local/lib/python3.11/dist-packages (from crawl4ai) (7.0.0)\n",
            "Requirement already satisfied: nltk>=3.9.1 in /usr/local/lib/python3.11/dist-packages (from crawl4ai) (3.9.1)\n",
            "Requirement already satisfied: rich>=13.9.4 in /usr/local/lib/python3.11/dist-packages (from crawl4ai) (13.9.4)\n",
            "Requirement already satisfied: cssselect>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from crawl4ai) (1.3.0)\n",
            "Requirement already satisfied: httpx>=0.27.2 in /usr/local/lib/python3.11/dist-packages (from crawl4ai) (0.28.1)\n",
            "Requirement already satisfied: fake-useragent>=2.0.3 in /usr/local/lib/python3.11/dist-packages (from crawl4ai) (2.2.0)\n",
            "Requirement already satisfied: click>=8.1.7 in /usr/local/lib/python3.11/dist-packages (from crawl4ai) (8.2.1)\n",
            "Requirement already satisfied: pyperclip>=1.8.2 in /usr/local/lib/python3.11/dist-packages (from crawl4ai) (1.9.0)\n",
            "Requirement already satisfied: chardet>=5.2.0 in /usr/local/lib/python3.11/dist-packages (from crawl4ai) (5.2.0)\n",
            "Requirement already satisfied: aiohttp>=3.11.11 in /usr/local/lib/python3.11/dist-packages (from crawl4ai) (3.12.15)\n",
            "Requirement already satisfied: brotli>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from crawl4ai) (1.1.0)\n",
            "Requirement already satisfied: humanize>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from crawl4ai) (4.12.3)\n",
            "Requirement already satisfied: lark>=1.2.2 in /usr/local/lib/python3.11/dist-packages (from crawl4ai) (1.2.2)\n",
            "Requirement already satisfied: alphashape>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from crawl4ai) (1.3.1)\n",
            "Requirement already satisfied: shapely>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from crawl4ai) (2.1.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.11.11->crawl4ai) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.11.11->crawl4ai) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.11.11->crawl4ai) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.11.11->crawl4ai) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.11.11->crawl4ai) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.11.11->crawl4ai) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.11.11->crawl4ai) (1.20.1)\n",
            "Requirement already satisfied: typing_extensions>=4.0 in /usr/local/lib/python3.11/dist-packages (from aiosqlite~=0.20->crawl4ai) (4.14.1)\n",
            "Requirement already satisfied: click-log>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from alphashape>=1.3.1->crawl4ai) (0.4.0)\n",
            "Requirement already satisfied: trimesh>=3.9.8 in /usr/local/lib/python3.11/dist-packages (from alphashape>=1.3.1->crawl4ai) (4.7.1)\n",
            "Requirement already satisfied: networkx>=2.5 in /usr/local/lib/python3.11/dist-packages (from alphashape>=1.3.1->crawl4ai) (3.5)\n",
            "Requirement already satisfied: rtree>=0.9.7 in /usr/local/lib/python3.11/dist-packages (from alphashape>=1.3.1->crawl4ai) (1.4.0)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from alphashape>=1.3.1->crawl4ai) (1.16.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4~=4.12->crawl4ai) (2.7)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.2->crawl4ai) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.2->crawl4ai) (2025.7.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.2->crawl4ai) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.2->crawl4ai) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.27.2->crawl4ai) (0.16.0)\n",
            "Requirement already satisfied: h2<5,>=3 in /usr/local/lib/python3.11/dist-packages (from httpx[http2]>=0.27.2->crawl4ai) (4.2.0)\n",
            "Requirement already satisfied: importlib-metadata>=6.8.0 in /usr/local/lib/python3.11/dist-packages (from litellm>=1.53.1->crawl4ai) (8.7.0)\n",
            "Requirement already satisfied: jinja2<4.0.0,>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from litellm>=1.53.1->crawl4ai) (3.1.6)\n",
            "Requirement already satisfied: jsonschema<5.0.0,>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from litellm>=1.53.1->crawl4ai) (4.25.0)\n",
            "Requirement already satisfied: openai>=1.68.2 in /usr/local/lib/python3.11/dist-packages (from litellm>=1.53.1->crawl4ai) (1.97.1)\n",
            "Requirement already satisfied: tiktoken>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from litellm>=1.53.1->crawl4ai) (0.9.0)\n",
            "Requirement already satisfied: tokenizers in /usr/local/lib/python3.11/dist-packages (from litellm>=1.53.1->crawl4ai) (0.21.4)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk>=3.9.1->crawl4ai) (1.5.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk>=3.9.1->crawl4ai) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk>=3.9.1->crawl4ai) (4.67.1)\n",
            "Requirement already satisfied: pyee<14,>=13 in /usr/local/lib/python3.11/dist-packages (from playwright>=1.49.0->crawl4ai) (13.0.0)\n",
            "Requirement already satisfied: greenlet<4.0.0,>=3.1.1 in /usr/local/lib/python3.11/dist-packages (from playwright>=1.49.0->crawl4ai) (3.2.3)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.10->crawl4ai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.10->crawl4ai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.10->crawl4ai) (0.4.1)\n",
            "Requirement already satisfied: cryptography<46,>=41.0.5 in /usr/local/lib/python3.11/dist-packages (from pyOpenSSL>=24.3.0->crawl4ai) (43.0.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests~=2.26->crawl4ai) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests~=2.26->crawl4ai) (2.5.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=13.9.4->crawl4ai) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=13.9.4->crawl4ai) (2.19.2)\n",
            "Requirement already satisfied: fake-http-header<0.4.0,>=0.3.5 in /usr/local/lib/python3.11/dist-packages (from tf-playwright-stealth>=1.1.0->crawl4ai) (0.3.5)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography<46,>=41.0.5->pyOpenSSL>=24.3.0->crawl4ai) (1.17.1)\n",
            "Requirement already satisfied: hyperframe<7,>=6.1 in /usr/local/lib/python3.11/dist-packages (from h2<5,>=3->httpx[http2]>=0.27.2->crawl4ai) (6.1.0)\n",
            "Requirement already satisfied: hpack<5,>=4.1 in /usr/local/lib/python3.11/dist-packages (from h2<5,>=3->httpx[http2]>=0.27.2->crawl4ai) (4.1.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata>=6.8.0->litellm>=1.53.1->crawl4ai) (3.23.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2<4.0.0,>=3.1.2->litellm>=1.53.1->crawl4ai) (3.0.2)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm>=1.53.1->crawl4ai) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm>=1.53.1->crawl4ai) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm>=1.53.1->crawl4ai) (0.26.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=13.9.4->crawl4ai) (0.1.2)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.68.2->litellm>=1.53.1->crawl4ai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.68.2->litellm>=1.53.1->crawl4ai) (0.10.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai>=1.68.2->litellm>=1.53.1->crawl4ai) (1.3.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers->litellm>=1.53.1->crawl4ai) (0.34.3)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography<46,>=41.0.5->pyOpenSSL>=24.3.0->crawl4ai) (2.22)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm>=1.53.1->crawl4ai) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm>=1.53.1->crawl4ai) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm>=1.53.1->crawl4ai) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm>=1.53.1->crawl4ai) (6.0.2)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm>=1.53.1->crawl4ai) (1.1.5)\n"
          ]
        }
      ],
      "source": [
        "!pip install crawl4ai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "6jc1u8VUgLv3",
        "outputId": "f2776bf7-1e37-465f-9fa5-5966e3a056dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hit:1 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Get:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "Hit:3 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:5 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Fetched 3,632 B in 2s (1,718 B/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "34 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "\u001b[1;33mW: \u001b[0mSkipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\u001b[0m\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "gnupg is already the newest version (2.2.27-3ubuntu2.4).\n",
            "wget is already the newest version (1.21.2-2ubuntu1.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 34 not upgraded.\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "chromium-chromedriver is already the newest version (1:85.0.4183.83-0ubuntu2.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 34 not upgraded.\n",
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.11/dist-packages (1.6.0)\n",
            "Requirement already satisfied: playwright in /usr/local/lib/python3.11/dist-packages (1.54.0)\n",
            "Requirement already satisfied: pyee<14,>=13 in /usr/local/lib/python3.11/dist-packages (from playwright) (13.0.0)\n",
            "Requirement already satisfied: greenlet<4.0.0,>=3.1.1 in /usr/local/lib/python3.11/dist-packages (from playwright) (3.2.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from pyee<14,>=13->playwright) (4.14.1)\n"
          ]
        }
      ],
      "source": [
        "!apt update\n",
        "!apt install -y wget gnupg\n",
        "!apt install -y chromium-chromedriver\n",
        "!pip install nest_asyncio playwright\n",
        "!playwright install chromium\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "EXGUKtoek9i5",
        "outputId": "f7b7a4e8-fbbe-4c1e-e9ef-0457cf5e6129"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080\">INIT</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">]</span><span style=\"color: #008080; text-decoration-color: #008080\">.... → Crawl4AI </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.7</span><span style=\"color: #008080; text-decoration-color: #008080\">.</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"color: #008080; text-decoration-color: #008080\"> </span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1;36m[\u001b[0m\u001b[36mINIT\u001b[0m\u001b[1;36m]\u001b[0m\u001b[36m...\u001b[0m\u001b[36m. → Crawl4AI \u001b[0m\u001b[1;36m0.7\u001b[0m\u001b[36m.\u001b[0m\u001b[1;36m2\u001b[0m\u001b[36m \u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">FETCH</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">]</span><span style=\"color: #008000; text-decoration-color: #008000\">... ↓ </span><span style=\"color: #008000; text-decoration-color: #008000; text-decoration: underline\">https://www.amazon.in/s?k=laptops</span><span style=\"color: #008000; text-decoration-color: #008000\">                                                                    |</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">✓ | ⏱: </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">19.</span><span style=\"color: #008000; text-decoration-color: #008000\">97s </span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1;32m[\u001b[0m\u001b[32mFETCH\u001b[0m\u001b[1;32m]\u001b[0m\u001b[32m...\u001b[0m\u001b[32m ↓ \u001b[0m\u001b[4;32mhttps://www.amazon.in/s?\u001b[0m\u001b[4;32mk\u001b[0m\u001b[4;32m=\u001b[0m\u001b[4;32mlaptops\u001b[0m\u001b[32m                                                                    |\u001b[0m\n",
              "\u001b[32m✓\u001b[0m\u001b[32m | ⏱: \u001b[0m\u001b[1;32m19.\u001b[0m\u001b[32m97s \u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">SCRAPE</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">]</span><span style=\"color: #008000; text-decoration-color: #008000\">.. ◆ </span><span style=\"color: #008000; text-decoration-color: #008000; text-decoration: underline\">https://www.amazon.in/s?k=laptops</span><span style=\"color: #008000; text-decoration-color: #008000\">                                                                    |</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">✓ | ⏱: </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">1.</span><span style=\"color: #008000; text-decoration-color: #008000\">40s </span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1;32m[\u001b[0m\u001b[32mSCRAPE\u001b[0m\u001b[1;32m]\u001b[0m\u001b[32m.. ◆ \u001b[0m\u001b[4;32mhttps://www.amazon.in/s?\u001b[0m\u001b[4;32mk\u001b[0m\u001b[4;32m=\u001b[0m\u001b[4;32mlaptops\u001b[0m\u001b[32m                                                                    |\u001b[0m\n",
              "\u001b[32m✓\u001b[0m\u001b[32m | ⏱: \u001b[0m\u001b[1;32m1.\u001b[0m\u001b[32m40s \u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">EXTRACT</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">]</span><span style=\"color: #008000; text-decoration-color: #008000\">. ■ </span><span style=\"color: #008000; text-decoration-color: #008000; text-decoration: underline\">https://www.amazon.in/s?k=laptops</span><span style=\"color: #008000; text-decoration-color: #008000\">                                                                    |</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">✓ | ⏱: </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">0.</span><span style=\"color: #008000; text-decoration-color: #008000\">68s </span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1;32m[\u001b[0m\u001b[32mEXTRACT\u001b[0m\u001b[1;32m]\u001b[0m\u001b[32m. ■ \u001b[0m\u001b[4;32mhttps://www.amazon.in/s?\u001b[0m\u001b[4;32mk\u001b[0m\u001b[4;32m=\u001b[0m\u001b[4;32mlaptops\u001b[0m\u001b[32m                                                                    |\u001b[0m\n",
              "\u001b[32m✓\u001b[0m\u001b[32m | ⏱: \u001b[0m\u001b[1;32m0.\u001b[0m\u001b[32m68s \u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">COMPLETE</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">]</span><span style=\"color: #008000; text-decoration-color: #008000\"> ● </span><span style=\"color: #008000; text-decoration-color: #008000; text-decoration: underline\">https://www.amazon.in/s?k=laptops</span><span style=\"color: #008000; text-decoration-color: #008000\">                                                                    |</span>\n",
              "<span style=\"color: #008000; text-decoration-color: #008000\">✓ | ⏱: </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">22.</span><span style=\"color: #008000; text-decoration-color: #008000\">07s </span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1;32m[\u001b[0m\u001b[32mCOMPLETE\u001b[0m\u001b[1;32m]\u001b[0m\u001b[32m ● \u001b[0m\u001b[4;32mhttps://www.amazon.in/s?\u001b[0m\u001b[4;32mk\u001b[0m\u001b[4;32m=\u001b[0m\u001b[4;32mlaptops\u001b[0m\u001b[32m                                                                    |\u001b[0m\n",
              "\u001b[32m✓\u001b[0m\u001b[32m | ⏱: \u001b[0m\u001b[1;32m22.\u001b[0m\u001b[32m07s \u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import asyncio, json, re\n",
        "import nest_asyncio; nest_asyncio.apply()\n",
        "\n",
        "from crawl4ai import AsyncWebCrawler\n",
        "from crawl4ai.extraction_strategy import JsonCssExtractionStrategy\n",
        "from crawl4ai.async_configs import BrowserConfig, CrawlerRunConfig\n",
        "\n",
        "def parse_specs(specs_str):\n",
        "    parts = [p.strip() for p in re.split(r'•|,', specs_str)]\n",
        "    out = {\"Inches\": None, \"ScreenResolution\": None, \"Cpu\": None,\n",
        "           \"Ram\": None, \"Memory\": None, \"Gpu\": None, \"OpSys\": None}\n",
        "    for part in parts:\n",
        "        if re.search(r'\\d+(\\.\\d+)?\\\"', part): out[\"Inches\"] = part\n",
        "        elif re.search(r'\\d{3,4}x\\d{3,4}', part): out[\"ScreenResolution\"] = part\n",
        "        elif re.search(r'Intel|AMD', part): out[\"Cpu\"] = part\n",
        "        elif re.search(r'GB RAM|GB DDR', part): out[\"Ram\"] = part\n",
        "        elif re.search(r'SSD|HDD', part): out[\"Memory\"] = part\n",
        "        elif re.search(r'Graphics|GPU', part): out[\"Gpu\"] = part\n",
        "        elif re.search(r'Windows|DOS|Ubuntu', part): out[\"OpSys\"] = part\n",
        "    return out\n",
        "\n",
        "async def main():\n",
        "    schema = {\n",
        "        \"name\": \"Amazon Laptop Specs\",\n",
        "        \"baseSelector\": \"[data-component-type='s-search-result']\",\n",
        "        \"fields\": [\n",
        "            {\"name\": \"ListingTitle\", \"selector\": \"h2 a span.a-text-normal\", \"type\": \"text\"},\n",
        "            {\"name\": \"Specs\",        \"selector\": \".a-size-base-plus.s-line-clamp-2\", \"type\": \"text\"},\n",
        "            {\"name\": \"Weight\",       \"selector\": \".a-size-base.s-line-clamp-2\",      \"type\": \"text\"},\n",
        "            {\"name\": \"Price\",        \"selector\": \".a-price .a-offscreen\",             \"type\": \"text\"}\n",
        "        ]\n",
        "    }\n",
        "\n",
        "    extractor = JsonCssExtractionStrategy(schema=schema)\n",
        "\n",
        "    browser_conf = BrowserConfig(headless=True)\n",
        "    run_conf = CrawlerRunConfig(\n",
        "        wait_for=\"css:[data-component-type='s-search-result']\",\n",
        "        extraction_strategy=extractor,\n",
        "        scan_full_page=True,\n",
        "        scroll_delay=1.0,\n",
        "        delay_before_return_html=2.0\n",
        "    )\n",
        "\n",
        "    url = \"https://www.amazon.in/s?k=laptops\"\n",
        "    async with AsyncWebCrawler(config=browser_conf) as crawler:\n",
        "        result = await crawler.arun(url=url, config=run_conf)\n",
        "        if not result.success:\n",
        "            print(\"❌ Crawl failed:\", result.error_message)\n",
        "            return\n",
        "\n",
        "        items = json.loads(result.extracted_content or \"[]\")\n",
        "        for idx, it in enumerate(items, 1):\n",
        "            specs = parse_specs(it.get(\"Specs\", \"\"))\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    asyncio.run(main())\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
